---
layout: page
title: Publications
---

<head>
<style>
a { text-decoration : none; }
a:hover { text-decoration : underline; }
a, a:visited { color : #0050e7; }
p { font-size : 16px; }
h3 { font-size : 18px; margin : 8; padding : 0; }
.publogo { width: 100 px; margin-right : 20px; float : left; border : 10px;}
.publication { clear : left; padding-bottom : 0px; }
.publication p { height : 180px; padding-top : 0px;}
.publication strong { font-size : 17px; color : #0000A0; }
.publication strong a { font-size : 17px; color : #0000A0; }
</style>
</head>

<!-- <a href="https://scholar.google.com/citations?user=SL--7UMAAAAJ&hl=en" target="_blank">Google Scholar</a>
<br> -->
<font color="grey" size="3">
  * Equal contribution. ✉ corresponding / co-corresponding author.
</font>

<h3>2023</h3>

<div class="publication">
  <img src="../static/pubs/UDA23.png" class="publogo" width="200 px" height="150 px">
  <p> 
    <strong>
    Unsupervised Domain Adaptation Approach for Vision-based Semantic Understanding of Bridge Inspection Scenes without Manual Annotations
    </strong>
    <br>
    Yasutaka Narazaki✉, Wendong Pang, Gaoang Wang, <b>Wenhao Chai</b>
    <br>
    <em>Under Review.</em>
    <br>
    <font color="grey" size="2">
    To facilitate the applications of deep learning-based visual recognition algorithms to bridge inspection tasks with limited manual efforts.
    </font>
  </p>
</div>

<div class="publication">
  <img src="../static/pubs/LAT23.png" class="publogo" width="200 px" height="150 px">
  <p> 
    <strong>
    Learning Action Tokens via Video Diffusion Models
    </strong>
    <br>
    <b>Wenhao Chai</b>, Xun Guo, Gaoang Wang, Yan Lu
    <br>
    <em>Under Review.</em>
    <br>
    <font color="grey" size="2">
    We are the first to introduce action token concept in video generation, which can learn actions or changes across time independent from objects.
    </font>
  </p>
</div>

<div class="publication">
  <img src="../static/pubs/FAN23.png" class="publogo" width="200 px" height="180 px">
  <p> 
      <strong>
      Five A+ Network: You Only Need 9K Parameters for Underwater Image Enhancement
      </strong>
      <br>
      Jingxia Jiang, Tian Ye, Jinbin Bai, Sixiang Chen, <b>Wenhao Chai</b>, Jun Shi, Yun Liu, Erkang Chen
      <br>
      <em>arXiv Preprint.</em>
      <br>
      <a href="https://arxiv.org/abs/2305.08824">[Paper]</a>
      <a href="https://github.com/Owen718/FiveAPlus-Network">[Code]</a>
      <img alt="NPM" src="https://img.shields.io/github/stars/Owen718/FiveAPlus-Network?style=social">
      <br>
      <font color="grey" size="2">
      A highly efficient and lightweight real-time underwater image enhancement network with only 9k parameters and 10ms processing time. 
      </font>
  </p>
</div>

<br>

<div class="publication">
  <img src="../static/pubs/SAL23.png" class="publogo" width="200 px" height="160 px">
  <p> 
    <strong>
    Sequential Affinity Learning for Video Restoration
    </strong>
    <br>
    Tian Ye, Sixiang Chen, Yun Liu, <b>Wenhao Chai</b>, Jinbin Bai, Wenbin Zou, Yunchen Zhang, Jiang Mingchao, Erkang Chen, Chenghao Xue  
    <br>
    <em>Under Review.</em>
    <br>
    <a href="https://github.com/Owen718/SALN">[Code]</a>
    <img alt="NPM" src="https://img.shields.io/github/stars/Owen718/SALN?style=social">
    <br>
    <font color="grey" size="2">
    Affinity mechanism establishes direct correspondences between the Query frame, degraded sequence, and restored frames in latent space.
    </font>
  </p>
</div>

<div class="publication">
  <img src="../static/pubs/PMP23.png" class="publogo" width="200 px" height="150 px">
  <p> 
    <strong>
    PoSynDA: Multi-Hypothesis Pose Synthesis Domain Adaptation for Enhanced 3D Human Pose Estimation
    </strong>
    <br>
    Hanbing Liu, Jun-Yan He, Zhi-Qi Cheng, Wangmeng Xiang, Qize Yang, <b>Wenhao Chai</b>, Gaoang Wang, Xu Bao, Bin Luo, Yifeng Geng, Xuansong Xie  
    <br>
    <em>Under Review.</em>
    <br>
    <font color="grey" size="2">
    PoSynDA offers a state-of-the-art domain adaptation solution for 3D pose estimation.
    </font>
  </p>
</div>

<div class="publication">
  <img src="../static/pubs/STC23.png" class="publogo" width="200 px" height="150 px">
  <p> 
    <strong>
    StableVideo: Text-driven Consistency-aware Diffusion Video Editing
    </strong>
    <br>
    <b>Wenhao Chai</b>, Xun Guo, Gaoang Wang, Yan Lu
    <br>
    <em>Under Review.</em>
    <br>
    <font color="grey" size="2">
    We tackle introduce temporal dependency to existing text-driven diffusion models, which allows them to generate consistent appearance for the new objects.
    </font>
  </p>
</div>

<div class="publication">
  <img src="../static/pubs/IRF23.png" class="publogo" width="200 px" height="180 px">
  <p> 
    <strong>
    Image Reference-guided Fashion Design with Structure-aware Transfer by Diffusion Models
    </strong>
    <br>
    Shidong Cao*, <b>Wenhao Chai*</b>, Shengyu Hao, Gaoang Wang✉
    <br>
    <em>[CVPRW 2023] 6th Workshop on Computer Vision for Fashion, Art, and Design</em>
    <br>
    <a href="https://openaccess.thecvf.com/content/CVPR2023W/CVFAD/html/Cao_Image_Reference-Guided_Fashion_Design_With_Structure-Aware_Transfer_by_Diffusion_Models_CVPRW_2023_paper.html">[Paper]</a>
    <a href="https://github.com/Rem105-210/DiffFashion">[Code]</a>
    <img alt="NPM" src="https://img.shields.io/github/stars/Rem105-210/DiffFashion?style=social">
    <br>
    <font color="grey" size="2">
    we aim to transfer a reference appearance image onto a clothing image while preserving the structure of the clothing image.
    </font>
  </p>
</div>

<br>

<div class="publication">
  <img src="../static/pubs/GAM23.png" class="publogo" width="200 px" height="150 px">
  <p> 
    <strong>
    Global Adaptation meets Local Generalization: Unsupervised Domain Adaptation for 3D Human Pose Estimation
    </strong>
    <br>
    <b>Wenhao Chai</b>, Zhongyu Jiang, Jenq-Neng Hwang, Gaoang Wang✉
    <br>
    <em>arXiv Preprint.</em>
    <br>
    <a href="https://arxiv.org/abs/2303.16456">[Paper]</a>
    <br>
    <font color="grey" size="2">
    A simple yet effective framework of unsupervised domain adaptation for 3D human pose estimation.
    </font>
  </p>
</div>

<div class="publication">
  <img src="../static/pubs/BIW23.png" class="publogo" width="200 px" height="150 px">
  <p> 
    <strong>
    Blind Inpainting with Object-aware Discrimination for Artificial Marker Removal
    </strong>
    <br>
    Xuechen Guo, Wenhao Hu, Chiming Ni, <b>Wenhao Chai</b>, Shiyan Li, Gaoang Wang✉
    <br>
    <em>arXiv Preprint.</em>
    <br>
    <a href="https://arxiv.org/abs/2303.15124">[Paper]</a>
    <br>
    <font color="grey" size="2">
    A novel blind inpainting network for artificial marker removal in medical images.
    </font>
  </p>
</div>

<div class="publication">
  <img src="../static/pubs/DLM23.png" class="publogo" width="200 px" height="180 px">
  <p> 
    <strong>
    Deep Learning Methods for Small Molecule Drug Discovery: A Survey
    </strong>
    <br>
    Wenhao Hu*, Yingying Liu*, Xuanyu Chen, <b>Wenhao Chai</b>, Hangyue Chen, Hongwei Wang✉, Gaoang Wang✉
    <br>
    <em>IEEE Transactions on Artificial Intelligence</em>
    <br>
    <a href="https://arxiv.org/abs/2303.00313">[Paper]</a>
    <br>
    <font color="grey" size="2">
    we present a comprehensive review on the aforementioned four aspects, and discuss the relationships among different applications.
    </font>
  </p>
</div>

<br>

<div class="publication">
  <img src="../static/pubs/IRF23.png" class="publogo" width="200 px" height="180 px">
  <p> 
    <strong>
    DiffFashion: Reference-based Fashion Design with Structure-aware Transfer by Diffusion Models
    </strong>
    <br>
    Shidong Cao*, <b>Wenhao Chai*</b>, Shengyu Hao, Yanting Zhang, Hangyue Chen✉, Gaoang Wang✉
    <br>
    <em>arXiv Preprint.</em>
    <br>
    <a href="https://arxiv.org/abs/2302.06826">[Paper]</a>
    <a href="https://github.com/Rem105-210/DiffFashion">[Code]</a>
    <img alt="NPM" src="https://img.shields.io/github/stars/Rem105-210/DiffFashion?style=social">
    <br>
    <font color="grey" size="2">
    we aim to transfer a reference appearance image onto a clothing image while preserving the structure of the clothing image.
    </font>
  </p>
</div>

<br>
<h3>2022</h3>

<div class="publication">
  <img src="../static/pubs/ASU22.png" class="publogo" width="200 px" height="200 px">
  <p> 
    <strong>
    Automatic Spinal Ultrasound Image Segmentation and Deployment for Real-time Spine Volumetric Reconstruction
    </strong>
    <br>
    Yifan Cao*, Chenghao Tan*, Wenzhuo Qian, <b>Wenhao Chai</b>, Luhang Cui, Wenxuan Yang, Xinben Hu✉, Yongjian Zhu, Wenhui Zhou✉, Xingfa Shen
    <br>
    <em>[ICUS 2022] IEEE International Conference on Unmanned Systems</em>
    <br>
    <font color="red" size="2">
    <em>Best Paper Award</em>
    </font>
    <br>
    <a href="https://ieeexplore.ieee.org/document/9987127">[Paper]</a>
    <a href="https://github.com/deeper-coder/ICUS-2022">[Code]</a>
    <img alt="NPM" src="https://img.shields.io/github/stars/deeper-coder/ICUS-2022?style=social">
    <br>
    <font color="grey" size="2">
    A real-time 3D spine volumetric reconstruction from spinal ultrasound images.
    </font>
  </p>
</div>

<br>

<div class="publication">
  <img src="../static/pubs/WST22.png" class="publogo" width="200 px" height="200 px">
  <p> 
    <strong>
    Weakly Supervised Two-Stage Training Scheme for Deep Video Fight Detection Model
    </strong>
    <br>
    Zhenting Qi*, Ruike Zhu*, Zheyu Fu*, <b>Wenhao Chai*</b>, Volodymyr Kindratenko✉ 
    <br>
    <em>[ICTAI 2022] IEEE International Conference on Tools with Artificial Intelligence</em>
    <br>
    <a href="https://arxiv.org/abs/2209.11477">[Paper]</a>
    <a href="https://github.com/Hepta-Col/VideoFightDetection">[Dataset]</a>
    <img alt="NPM" src="https://img.shields.io/github/stars/Hepta-Col/VideoFightDetection?style=social">
    <br>
    <font color="grey" size="2">
    We collect a new dataset, VFD-2000, that specializes in video fight detection, with a larger scale and more scenarios.
    </font>
  </p>
</div>

<br>

<div class="publication">
  <img src="../static/pubs/DVM22.png" class="publogo" width="200 px" height="160 px">
  <p> 
    <strong>
    Deep Vision Multimodal Learning: Methodology, Benchmark, and Trend
    </strong>
    <br>
    <b>Wenhao Chai</b>, Gaoang Wang✉
    <br>
    <em>Applied Sciences</em>
    <br>
    <a href="https://www.mdpi.com/2076-3417/12/13/6588">[Paper]</a>
    <br>
    <font color="grey" size="2">
    With the fast development of deep learning, vision multimodal learning has gained much interest from the community.
    </font>
  </p>
</div>
